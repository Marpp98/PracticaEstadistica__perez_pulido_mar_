{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c7beb6",
   "metadata": {},
   "source": [
    "# Limpieza de datos de National Health and Nutrition Survey para análisis estadístico\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ef84d",
   "metadata": {},
   "source": [
    "El presente notebook se centra en la limpieza y normalización de las variables para crear el dataset posteriormente utilizado en el archivo [Practica_estadistica.](PracticaEstadistica__perez_pulido_mar_.ipynb)\n",
    "Los datos han sido extraidos de la web de [NHANES](https://wwwn.cdc.gov/nchs/nhanes/), en la cual se han seleccionado los periodos desde 2007 hasta 2023.\n",
    "\n",
    "Como el objetivo es poder crear un modelo que prediga el nivel de depresion, los dataset escogidos para cada periodo han sido:\n",
    "- *Demographic Variables and Sample Weights*\n",
    "- *Mental Health - Depression Screener*\n",
    "- *Phisical Activity*\n",
    "- *Sleep Disorders*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f73ecf",
   "metadata": {},
   "source": [
    "### 0. Importaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09af7983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones ejecutadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "\n",
    "import src.transformaciones as tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f375d2e",
   "metadata": {},
   "source": [
    "### 1. Carga y visualización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e65a2a",
   "metadata": {},
   "source": [
    "Para optimizar el código y evitar cargar cada dataset de forma individual, se ha optado por crear un diccionario en el que se ha incluido el periodo representativo de cada archivo para usarlo posteriormente como columna. También se han seleccionado las columnas necesarias para la construcción de este dataset tras un previo análisis manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe681ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44931, 25)\n"
     ]
    }
   ],
   "source": [
    "cycles = [\n",
    "    {\"cycle\": \"2007-2008\", \"phq\": \"../data/2007-2008/DPQ_E.xpt\", \"demo\": \"../data/2007-2008/DEMO_E.xpt\", \"sleep\": \"../data/2007-2008/SLQ_E.xpt\", \"activity\": \"../data/2007-2008/PAQ_E.xpt\"},\n",
    "    {\"cycle\": \"2009-2010\", \"phq\": \"../data/2009-2010/DPQ_F.xpt\", \"demo\": \"../data/2009-2010/DEMO_F.xpt\", \"sleep\": \"../data/2009-2010/SLQ_F.xpt\", \"activity\": \"../data/2009-2010/PAQ_F.xpt\"},\n",
    "    {\"cycle\": \"2011-2012\", \"phq\": \"../data/2011-2012/DPQ_G.xpt\", \"demo\": \"../data/2011-2012/DEMO_G.xpt\", \"sleep\": \"../data/2011-2012/SLQ_G.xpt\", \"activity\": \"../data/2011-2012/PAQ_G.xpt\"},\n",
    "    {\"cycle\": \"2013-2014\", \"phq\": \"../data/2013-2014/DPQ_H.xpt\", \"demo\": \"../data/2013-2014/DEMO_H.xpt\", \"sleep\": \"../data/2013-2014/SLQ_H.xpt\", \"activity\": \"../data/2013-2014/PAQ_H.xpt\"},\n",
    "    {\"cycle\": \"2015-2016\", \"phq\": \"../data/2015-2016/DPQ_I.xpt\", \"demo\": \"../data/2015-2016/DEMO_I.xpt\", \"sleep\": \"../data/2015-2016/SLQ_I.xpt\", \"activity\": \"../data/2015-2016/PAQ_I.xpt\"},\n",
    "    {\"cycle\": \"2017-2020\", \"phq\": \"../data/2017-2020/P_DPQ.xpt\", \"demo\": \"../data/2017-2020/P_DEMO.xpt\", \"sleep\": \"../data/2017-2020/P_SLQ.xpt\", \"activity\": \"../data/2017-2020/P_PAQ.xpt\"},\n",
    "    {\"cycle\": \"2021-2023\", \"phq\": \"../data/2021-2023/DPQ_L.xpt\", \"demo\": \"../data/2021-2023/DEMO_L.xpt\", \"sleep\": \"../data/2021-2023/SLQ_L.xpt\", \"activity\": \"../data/2021-2023/PAQ_L.xpt\"}\n",
    "\n",
    "]\n",
    "\n",
    "phq_cols = [\n",
    "    \"SEQN\",\n",
    "    \"DPQ010\",\n",
    "    \"DPQ020\",\n",
    "    \"DPQ030\",\n",
    "    \"DPQ040\",\n",
    "    \"DPQ050\",\n",
    "    \"DPQ060\",\n",
    "    \"DPQ070\",\n",
    "    \"DPQ080\",\n",
    "    \"DPQ090\",\n",
    "    \"DPQ100\"\n",
    "]\n",
    "\n",
    "demo_cols = [\n",
    "    \"SEQN\",\n",
    "    \"RIDAGEYR\",\n",
    "    \"RIAGENDR\",\n",
    "    \"RIDRETH1\",\n",
    "    \"DMDEDUC2\",\n",
    "    \"DMDMARTL\",\n",
    "    \"DMDMARTZ\",   \n",
    "    \"INDFMPIR\"\n",
    "]\n",
    "\n",
    "sleep_cols = [\n",
    "    \"SEQN\",\n",
    "    \"SLD010H\",\n",
    "    \"SLD012\"\n",
    "]\n",
    "\n",
    "activity_cols = [\n",
    "    \"SEQN\",\n",
    "    \"PAD800\",\n",
    "    \"PAD820\",\n",
    "    \"PAD675\",\n",
    "    \"PAD660\"\n",
    "\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "\n",
    "for c in cycles:\n",
    "    # Cargar PHQ-9, demografía, sueñi y actividad física\n",
    "    df_phq = pd.read_sas(c[\"phq\"], format=\"xport\")\n",
    "    df_demo = pd.read_sas(c[\"demo\"], format=\"xport\")\n",
    "    df_sleep = pd.read_sas(c[\"sleep\"], format=\"xport\")\n",
    "    df_activity = pd.read_sas(c[\"activity\"], format=\"xport\")\n",
    "\n",
    "\n",
    "    # Seleccionar solo columnas indicadas\n",
    "    df_phq = df_phq[[col for col in phq_cols if col in df_phq.columns]]\n",
    "    df_demo = df_demo[[col for col in demo_cols if col in df_demo.columns]]\n",
    "    df_sleep = df_sleep[[col for col in sleep_cols if col in df_sleep.columns]]\n",
    "    df_activity = df_activity[[col for col in activity_cols if col in df_activity.columns]]\n",
    "    \n",
    "    # Merge por SEQN(id)\n",
    "    df_merged = df_phq.merge(df_demo, on=\"SEQN\", how=\"left\")\n",
    "    df_merged = df_merged.merge(df_sleep, on=\"SEQN\", how=\"left\")\n",
    "    df_merged = df_merged.merge(df_activity, on=\"SEQN\", how=\"left\")\n",
    "    \n",
    "    # Añadir columna ciclo\n",
    "    df_merged[\"ciclo\"] = c[\"cycle\"]\n",
    "    \n",
    "    # Guardar en la lista\n",
    "    dfs.append(df_merged)\n",
    "\n",
    "\n",
    "# Concatenar todos los ciclos\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447e14a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>DPQ010</th>\n",
       "      <th>DPQ020</th>\n",
       "      <th>DPQ030</th>\n",
       "      <th>DPQ040</th>\n",
       "      <th>DPQ050</th>\n",
       "      <th>DPQ060</th>\n",
       "      <th>DPQ070</th>\n",
       "      <th>DPQ080</th>\n",
       "      <th>DPQ090</th>\n",
       "      <th>...</th>\n",
       "      <th>DMDMARTL</th>\n",
       "      <th>INDFMPIR</th>\n",
       "      <th>SLD010H</th>\n",
       "      <th>PAD675</th>\n",
       "      <th>PAD660</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>SLD012</th>\n",
       "      <th>DMDMARTZ</th>\n",
       "      <th>PAD800</th>\n",
       "      <th>PAD820</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41475.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41477.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41479.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41481.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41482.0</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN        DPQ010        DPQ020        DPQ030        DPQ040  \\\n",
       "0  41475.0  1.000000e+00  5.397605e-79  1.000000e+00  1.000000e+00   \n",
       "1  41477.0  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79   \n",
       "2  41479.0  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79   \n",
       "3  41481.0  5.397605e-79  5.397605e-79  1.000000e+00  1.000000e+00   \n",
       "4  41482.0  9.000000e+00  1.000000e+00  1.000000e+00  5.397605e-79   \n",
       "\n",
       "         DPQ050        DPQ060        DPQ070        DPQ080        DPQ090  ...  \\\n",
       "0  1.000000e+00  1.000000e+00  5.397605e-79  5.397605e-79  5.397605e-79  ...   \n",
       "1  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  ...   \n",
       "2  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  ...   \n",
       "3  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  ...   \n",
       "4  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  ...   \n",
       "\n",
       "   DMDMARTL  INDFMPIR  SLD010H  PAD675  PAD660      ciclo  SLD012  DMDMARTZ  \\\n",
       "0       1.0      1.83      6.0     NaN     NaN  2007-2008     NaN       NaN   \n",
       "1       1.0      1.50      8.0     NaN     NaN  2007-2008     NaN       NaN   \n",
       "2       1.0      2.20      6.0     NaN     NaN  2007-2008     NaN       NaN   \n",
       "3       5.0      1.63      6.0     NaN   300.0  2007-2008     NaN       NaN   \n",
       "4       1.0      4.01      8.0    30.0     NaN  2007-2008     NaN       NaN   \n",
       "\n",
       "   PAD800  PAD820  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0121eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44931 entries, 0 to 44930\n",
      "Data columns (total 25 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SEQN      44931 non-null  float64\n",
      " 1   DPQ010    40368 non-null  float64\n",
      " 2   DPQ020    40360 non-null  float64\n",
      " 3   DPQ030    40356 non-null  float64\n",
      " 4   DPQ040    40349 non-null  float64\n",
      " 5   DPQ050    40348 non-null  float64\n",
      " 6   DPQ060    40342 non-null  float64\n",
      " 7   DPQ070    40338 non-null  float64\n",
      " 8   DPQ080    40337 non-null  float64\n",
      " 9   DPQ090    40329 non-null  float64\n",
      " 10  DPQ100    27609 non-null  float64\n",
      " 11  RIDAGEYR  44931 non-null  float64\n",
      " 12  RIAGENDR  44931 non-null  float64\n",
      " 13  RIDRETH1  44931 non-null  float64\n",
      " 14  DMDEDUC2  42755 non-null  float64\n",
      " 15  DMDMARTL  28147 non-null  float64\n",
      " 16  INDFMPIR  40111 non-null  float64\n",
      " 17  SLD010H   23877 non-null  float64\n",
      " 18  PAD675    15306 non-null  float64\n",
      " 19  PAD660    8824 non-null   float64\n",
      " 20  ciclo     44931 non-null  object \n",
      " 21  SLD012    20865 non-null  float64\n",
      " 22  DMDMARTZ  14607 non-null  float64\n",
      " 23  PAD800    5031 non-null   float64\n",
      " 24  PAD820    2877 non-null   float64\n",
      "dtypes: float64(24), object(1)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a90941",
   "metadata": {},
   "source": [
    "## 2. Limpieza de valores no válidos y/o nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6feb88",
   "metadata": {},
   "source": [
    "Tal y como se muestra en la exploración previa, una de las características de estos archivos es que presentan valores ínfimos los cuales no pertenecen a ninguna de las escalas indicadas en la documentación de los datos. Estos datos aparecen al leer archivos SAS en Python y representan un valor cercano a 0 o un error en la lectura de los datos. \n",
    "\n",
    "A pesar de que en la documentación existe 0 como valor, no se han imputado como 0 ya que no se puede asegurar que sean datos válidos. Pasándolos a Nan, se evita crear sesgos.\n",
    "\n",
    "En cuanto al orden de la limpieza se ha ido haciendo por las columnas correspondientes a cada fichero para una mayor facilidad de entendimiento. Además, la interpretación de valores correspondientes a 'prefiero no contestar' o 'desconocido' van variando entre los ficheros, por ejemplo, para el caso de las preguntas del test de Depresión son valores no contestados aquellos pertenecientes a 7,9,77 y 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53352790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar códigos inválidos por NaN para las columnas de phq\n",
    "df_all[phq_cols] = df_all[phq_cols].replace([7, 9, 77, 99], np.nan)\n",
    "\n",
    "# Reemplazar valores extremadamente pequeños por NaN\n",
    "df_all[phq_cols] = df_all[phq_cols].map(lambda x: np.nan if abs(x)<1e-10 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d6e40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de nulos de SEQN = 0.0\n",
      "Porcentaje de nulos de DPQ010 = 76.16\n",
      "Porcentaje de nulos de DPQ020 = 76.63\n",
      "Porcentaje de nulos de DPQ030 = 64.0\n",
      "Porcentaje de nulos de DPQ040 = 54.39\n",
      "Porcentaje de nulos de DPQ050 = 76.45\n",
      "Porcentaje de nulos de DPQ060 = 83.11\n",
      "Porcentaje de nulos de DPQ070 = 83.38\n",
      "Porcentaje de nulos de DPQ080 = 89.72\n",
      "Porcentaje de nulos de DPQ090 = 96.36\n",
      "Porcentaje de nulos de DPQ100 = 82.36\n",
      "Porcentaje de nulos de RIDAGEYR = 0.0\n",
      "Porcentaje de nulos de RIAGENDR = 0.0\n",
      "Porcentaje de nulos de RIDRETH1 = 0.0\n",
      "Porcentaje de nulos de DMDEDUC2 = 4.84\n",
      "Porcentaje de nulos de DMDMARTL = 37.36\n",
      "Porcentaje de nulos de INDFMPIR = 10.73\n",
      "Porcentaje de nulos de SLD010H = 46.86\n",
      "Porcentaje de nulos de PAD675 = 65.93\n",
      "Porcentaje de nulos de PAD660 = 80.36\n",
      "Porcentaje de nulos de ciclo = 0.0\n",
      "Porcentaje de nulos de SLD012 = 53.56\n",
      "Porcentaje de nulos de DMDMARTZ = 67.49\n",
      "Porcentaje de nulos de PAD800 = 88.8\n",
      "Porcentaje de nulos de PAD820 = 93.6\n"
     ]
    }
   ],
   "source": [
    "tr.calculo_nulos(df_all, df_all.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7fafd",
   "metadata": {},
   "source": [
    "Los nombres de las columnas pueden ir variando a lo largo de los periodos para datasets que hacen referencia a lo mismo. Es por ello que se imputarn dichos valores en la columna que menos nulos tengan y se eliminará aquella que duplica la información y que presenta un mayor porcentaje de nulos.\n",
    "\n",
    "\n",
    "De este modo, las columnas a mantener después de impurtar los valores son:\n",
    "- DMDMARTL es equivalente a DMDMARTZ.\n",
    "- PAD800 es equivalente a PAD675\n",
    "- PAD820 es equivalente a PAD660\n",
    "- SLD012 es equivalente a SLD010H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999a8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"DMDMARTL\"] = df_all[\"DMDMARTL\"].fillna(df_all[\"DMDMARTZ\"])\n",
    "df_all[\"PAD675\"] = df_all[\"PAD675\"].fillna(df_all[\"PAD800\"])\n",
    "df_all[\"PAD660\"] = df_all[\"PAD660\"].fillna(df_all[\"PAD820\"])\n",
    "df_all[\"SLD010H\"] = df_all[\"SLD010H\"].fillna(df_all[\"SLD012\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f41491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(columns=[\"DMDMARTZ\", \"PAD800\", \"PAD820\", \"SLD012\" ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4074c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de nulos de SEQN = 0.0\n",
      "Porcentaje de nulos de DPQ010 = 76.16\n",
      "Porcentaje de nulos de DPQ020 = 76.63\n",
      "Porcentaje de nulos de DPQ030 = 64.0\n",
      "Porcentaje de nulos de DPQ040 = 54.39\n",
      "Porcentaje de nulos de DPQ050 = 76.45\n",
      "Porcentaje de nulos de DPQ060 = 83.11\n",
      "Porcentaje de nulos de DPQ070 = 83.38\n",
      "Porcentaje de nulos de DPQ080 = 89.72\n",
      "Porcentaje de nulos de DPQ090 = 96.36\n",
      "Porcentaje de nulos de DPQ100 = 82.36\n",
      "Porcentaje de nulos de RIDAGEYR = 0.0\n",
      "Porcentaje de nulos de RIAGENDR = 0.0\n",
      "Porcentaje de nulos de RIDRETH1 = 0.0\n",
      "Porcentaje de nulos de DMDEDUC2 = 4.84\n",
      "Porcentaje de nulos de DMDMARTL = 4.85\n",
      "Porcentaje de nulos de INDFMPIR = 10.73\n",
      "Porcentaje de nulos de SLD010H = 0.42\n",
      "Porcentaje de nulos de PAD675 = 54.74\n",
      "Porcentaje de nulos de PAD660 = 73.96\n",
      "Porcentaje de nulos de ciclo = 0.0\n"
     ]
    }
   ],
   "source": [
    "tr.calculo_nulos(df_all, df_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fb68b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44931, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2e5b9",
   "metadata": {},
   "source": [
    "Siguiendo con la limpieza de nulos perteneciente a las columnas de las preguntas del test de Depresión se opta por eliminar todas aquellas que presentan valores nulos en todas las filas ya que no aportan ningún tipo de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3965f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27638, 21)\n"
     ]
    }
   ],
   "source": [
    "preguntas_phq = ['DPQ010',\n",
    " 'DPQ020',\n",
    " 'DPQ030',\n",
    " 'DPQ040',\n",
    " 'DPQ050',\n",
    " 'DPQ060',\n",
    " 'DPQ070',\n",
    " 'DPQ080',\n",
    " 'DPQ090',\n",
    " 'DPQ100']\n",
    "\n",
    "# Eliminar las filas con nulos en todas las columnas del test PHQ_9\n",
    "df = df_all.dropna(subset=preguntas_phq, how=\"all\")\n",
    "\n",
    "# Comprobamos de nuevo la cantidad de filas tras su eliminación\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51632561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de nulos de DPQ010 = 76.16\n",
      "Porcentaje de nulos de DPQ020 = 76.63\n",
      "Porcentaje de nulos de DPQ030 = 64.0\n",
      "Porcentaje de nulos de DPQ040 = 54.39\n",
      "Porcentaje de nulos de DPQ050 = 76.45\n",
      "Porcentaje de nulos de DPQ060 = 83.11\n",
      "Porcentaje de nulos de DPQ070 = 83.38\n",
      "Porcentaje de nulos de DPQ080 = 89.72\n",
      "Porcentaje de nulos de DPQ090 = 96.36\n",
      "Porcentaje de nulos de DPQ100 = 82.36\n"
     ]
    }
   ],
   "source": [
    "tr.calculo_nulos(df_all, df_all[preguntas_phq].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e0f199",
   "metadata": {},
   "source": [
    "Pasando a la limpieza de los datos demográficos usando el mismo procedimiento, se observa que en este caso los datos no válidos corresponden a 77 y 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24242713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos las columnas de los datos demograficos, previa copia de seguridad\n",
    "df = df.copy()\n",
    "\n",
    "demo_cols = [\"INDFMPIR\",\"DMDEDUC2\",\"DMDMARTL\"]\n",
    "\n",
    "df[demo_cols] = df[demo_cols].replace([77,99], np.nan)\n",
    "df[demo_cols] = df[demo_cols].map(lambda x: np.nan if abs(x)<1e-10 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca88b4",
   "metadata": {},
   "source": [
    "Para las columnas representativas de Problemas de Sueño y Actividad Física se debe tener en cuenta también sus peculiaridades respecto a los valores no válidos que corresponden a 99.0 y 7777 y 9999 respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97d8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpiamos las columnas de los datos de sueño y actividad\n",
    "cols_sueño = ['SLD010H']\n",
    "cols_act = ['PAD675','PAD660']\n",
    "\n",
    "df[cols_sueño] = df[cols_sueño].replace([99.0], np.nan)\n",
    "df[cols_sueño] = df[cols_sueño].map(lambda x: np.nan if abs(x)<1e-10 else x)\n",
    "\n",
    "df[cols_act] = df[cols_act].replace([7777,9999], np.nan)\n",
    "df[cols_act] = df[cols_act].map(lambda x: np.nan if abs(x)<1e-10 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2176b",
   "metadata": {},
   "source": [
    "Centrándonos en la parte de actividad física existen dos columnas que representan tiempo dedicado a hacer ejercicio de forma moderada o intensa. Como el dato que interesa es saber los minutos que dedican al día y no su intensidad, se procede a sumar ambas variables para obtener una nueva y eliminamos las anteriores para evitar ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a72450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una variable que unifique el tiempo en minutos dedicado a hacer actividades fisicas independientemente de su intensidad\n",
    "df[\"min_actividad_diaria\"] = np.where(\n",
    "    df[[\"PAD675\", \"PAD660\"]].isna().all(axis=1),\n",
    "    np.nan,\n",
    "    df[\"PAD675\"].fillna(0) + df[\"PAD660\"].fillna(0)\n",
    ")\n",
    "\n",
    "# Eliminamos las columnas que ya no nos interesan:\n",
    "df.drop(columns=['PAD675','PAD660'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f274f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEQN                     0.000000\n",
       "DPQ010                  61.238150\n",
       "DPQ020                  62.012447\n",
       "DPQ030                  41.468268\n",
       "DPQ040                  25.852088\n",
       "DPQ050                  61.715754\n",
       "DPQ060                  72.545047\n",
       "DPQ070                  72.979231\n",
       "DPQ080                  83.280266\n",
       "DPQ090                  94.076995\n",
       "DPQ100                  71.325711\n",
       "RIDAGEYR                 0.000000\n",
       "RIAGENDR                 0.000000\n",
       "RIDRETH1                 0.000000\n",
       "DMDEDUC2                 5.546711\n",
       "DMDMARTL                 5.608221\n",
       "INDFMPIR                10.521745\n",
       "SLD010H                  0.539113\n",
       "ciclo                    0.000000\n",
       "min_actividad_diaria    48.748100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e42b1a",
   "metadata": {},
   "source": [
    "## 3. Creación target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19481b26",
   "metadata": {},
   "source": [
    "Antes de continuar imputando o limpiando nulos, necesitamos obtener la columna objetivo. \n",
    "\n",
    "Mediante la encuesta PHQ9 se consigue el valor numérico respecto al nivel de depresión que puede padecer una persona. Dicho dato se obtiene sumando las preguntas realizadas en ese test sobre sus percepciones a excepción de la columna DPQ100, que es una representación de cómo le afecta esa sintomatología.\n",
    "\n",
    "Es por ello que para obtener el datos será necesario tener las columnas correspondientes a las respuestas respondidas.\n",
    "\n",
    "Como solo hay 436 columnas completas al 100% se opta por imputar la media individual a aquellos valores faltantes siempre y cuando tengan completas 8 de las nueve preguntas, es decir, que al datos faltante de una columna de ese test se le imputará la media respecto a lo que haya completado en las otras preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec525b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con PHQ-9 completo: 436\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las columnas que se usan para el calculo del PHQ_9 score.\n",
    "phq = ['DPQ010',\n",
    " 'DPQ020',\n",
    " 'DPQ030',\n",
    " 'DPQ040',\n",
    " 'DPQ050',\n",
    " 'DPQ060',\n",
    " 'DPQ070',\n",
    " 'DPQ080',\n",
    " 'DPQ090']\n",
    "\n",
    "# Número de filas con PHQ-9 completo\n",
    "n_completas = df[phq].notna().all(axis=1).sum()\n",
    "\n",
    "print(\"Filas con PHQ-9 completo:\", n_completas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b8565e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos puntuaciones medias individuales para aquellos que han rellenado al menos 8 de las 9 preguntas\n",
    "# Para ello comprobamos primeros cuales son dichas filas y el resto las eliminamos\n",
    "\n",
    "df_valid = df.copy()\n",
    "\n",
    "df_valid[\"phq_answered\"] = df_valid[phq].notna().sum(axis=1)\n",
    "\n",
    "df_valid = df_valid[df_valid[\"phq_answered\"] >= 8].copy()\n",
    "\n",
    "# Eliminamos la columna que indica el número de columnas respondidas\n",
    "df_valid.drop(columns=[\"phq_answered\"], inplace=True)\n",
    "\n",
    "\n",
    "# Aplicamos la media y redondeamos porque los valores solo pueden ir de 0 a 3, sin decimales\n",
    "df_valid[phq] = (df_valid[phq].apply(lambda row: row.fillna(row.mean()), axis=1).round())\n",
    "\n",
    "# Obtenemos el target\n",
    "df_valid[\"PHQ9_score\"] = df_valid[phq].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476c5b7",
   "metadata": {},
   "source": [
    "## 4. Normalización de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa2359",
   "metadata": {},
   "source": [
    "Se procede a cambiar los tipos de datos a enteros para aquellos que representan respuestas de 0 a 3 ó 6, según la pregunta. el índice que identifica a cada encuestado también pasa a ser un entero y la categoría ciclo pasa a ser 'category'.\n",
    "\n",
    "Esto permite reflejar mejor la naturaleza de los datos, además de mejorar la consistencia y el uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0f7dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1529 entries, 14 to 44906\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   SEQN                  1529 non-null   float64\n",
      " 1   DPQ010                1529 non-null   float64\n",
      " 2   DPQ020                1529 non-null   float64\n",
      " 3   DPQ030                1529 non-null   float64\n",
      " 4   DPQ040                1529 non-null   float64\n",
      " 5   DPQ050                1529 non-null   float64\n",
      " 6   DPQ060                1529 non-null   float64\n",
      " 7   DPQ070                1529 non-null   float64\n",
      " 8   DPQ080                1529 non-null   float64\n",
      " 9   DPQ090                1529 non-null   float64\n",
      " 10  DPQ100                1369 non-null   float64\n",
      " 11  RIDAGEYR              1529 non-null   float64\n",
      " 12  RIAGENDR              1529 non-null   float64\n",
      " 13  RIDRETH1              1529 non-null   float64\n",
      " 14  DMDEDUC2              1433 non-null   float64\n",
      " 15  DMDMARTL              1431 non-null   float64\n",
      " 16  INDFMPIR              1347 non-null   float64\n",
      " 17  SLD010H               1507 non-null   float64\n",
      " 18  ciclo                 1529 non-null   object \n",
      " 19  min_actividad_diaria  605 non-null    float64\n",
      " 20  PHQ9_score            1529 non-null   float64\n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 262.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44b4fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1529 entries, 14 to 44906\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   SEQN                  1529 non-null   Int64   \n",
      " 1   DPQ010                1529 non-null   Int64   \n",
      " 2   DPQ020                1529 non-null   Int64   \n",
      " 3   DPQ030                1529 non-null   Int64   \n",
      " 4   DPQ040                1529 non-null   Int64   \n",
      " 5   DPQ050                1529 non-null   Int64   \n",
      " 6   DPQ060                1529 non-null   Int64   \n",
      " 7   DPQ070                1529 non-null   Int64   \n",
      " 8   DPQ080                1529 non-null   Int64   \n",
      " 9   DPQ090                1529 non-null   Int64   \n",
      " 10  DPQ100                1369 non-null   Int64   \n",
      " 11  RIDAGEYR              1529 non-null   Int64   \n",
      " 12  RIAGENDR              1529 non-null   Int64   \n",
      " 13  RIDRETH1              1529 non-null   Int64   \n",
      " 14  DMDEDUC2              1433 non-null   Int64   \n",
      " 15  DMDMARTL              1431 non-null   Int64   \n",
      " 16  INDFMPIR              1347 non-null   float64 \n",
      " 17  SLD010H               1507 non-null   float64 \n",
      " 18  ciclo                 1529 non-null   category\n",
      " 19  min_actividad_diaria  605 non-null    float64 \n",
      " 20  PHQ9_score            1529 non-null   float64 \n",
      "dtypes: Int64(16), category(1), float64(4)\n",
      "memory usage: 276.6 KB\n"
     ]
    }
   ],
   "source": [
    "columnas_int = phq_cols + ['RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'DMDEDUC2', 'DMDMARTL']\n",
    "df_valid = tr.cambiar_tipos(df_valid,['ciclo'],columnas_int)\n",
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b82eb",
   "metadata": {},
   "source": [
    "El último paso antes de exportar el fichero es pasar las columnas a títulos que sean significativos para poder realizar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a443b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid=df_valid.rename(columns = {'SEQN': 'id', \n",
    "                               'DPQ010': 'perdida_interes', \n",
    "                               'DPQ020': 'estado_animo', \n",
    "                               'DPQ030': 'alteraciones_sueño', \n",
    "                               'DPQ040': 'fatiga', \n",
    "                               'DPQ050': 'cambios_apetito', \n",
    "                               'DPQ060': 'sentimiento_inutilidad/culpa',\n",
    "                                'DPQ070': 'dificultades_concentracion', \n",
    "                                'DPQ080': 'inquietud/lentitud_motora', \n",
    "                                'DPQ090': 'ideacion_suicida', \n",
    "                                'DPQ100': 'impacto_funcional_sintomas', \n",
    "                                'RIDAGEYR': 'edad', \n",
    "                                'RIAGENDR': 'genero',\n",
    "                                'RIDRETH1': 'etnia', \n",
    "                                'DMDEDUC2': 'educacion', \n",
    "                                'DMDMARTL': 'estado_civil', \n",
    "                                'INDFMPIR': 'indice_ingresos_familiares', \n",
    "                                'SLD010H': 'horas_sueño'\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67499e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'perdida_interes', 'estado_animo', 'alteraciones_sueño', 'fatiga',\n",
       "       'cambios_apetito', 'sentimiento_inutilidad/culpa',\n",
       "       'dificultades_concentracion', 'inquietud/lentitud_motora',\n",
       "       'ideacion_suicida', 'impacto_funcional_sintomas', 'edad', 'genero',\n",
       "       'etnia', 'educacion', 'estado_civil', 'indice_ingresos_familiares',\n",
       "       'horas_sueño', 'ciclo', 'min_actividad_diaria', 'PHQ9_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81b38e",
   "metadata": {},
   "source": [
    "## 4. Exportación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211640a4",
   "metadata": {},
   "source": [
    "El último paso antes de realizar el análisis estadístico es transportar los datos a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "626e3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.to_csv(\"../data/nhanes_depression_dataset.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
